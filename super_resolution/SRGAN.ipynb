{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e9520d-ed3c-499e-9e81-91fbc0ab4610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import tqdm\n",
    "import PIL\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "torch.backends.cudnn.benchmark =  True\n",
    "torch.backends.cudnn.enabled =  True\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9275275c-f04b-4984-b7c1-4e7b1075d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_res_dim = 256\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(high_res_dim),\n",
    "    transforms.CenterCrop(high_res_dim),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "dataset = ImageFolder('/home/aditya/Datasets/flikr8k/', transform=preprocess)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=40, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0938b06-f006-47e9-84f9-4be7fbad3a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(dataloader))\n",
    "fig = plt.figure()\n",
    "rows = 2\n",
    "cols = 3\n",
    "for ii in range(1, rows*cols + 1, 1):\n",
    "    fig.add_subplot(rows, cols, ii)\n",
    "    plt.imshow(images[ii].permute(1, 2, 0))\n",
    "    plt.axis('off') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e37780-dcd2-444a-accd-ec4860c4a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        return torch.add(out, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8778c0ea-6f95-4bc3-a883-0f8ddabe5f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, stride=1, padding=4, bias=False)\n",
    "        self.prelu = nn.PReLU()\n",
    "\n",
    "        self.resblock1 = ResidualBlock(64, 64)\n",
    "\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                   nn.BatchNorm2d(64)\n",
    "                                  )\n",
    "\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                   nn.PixelShuffle(2),\n",
    "                                   nn.PReLU()\n",
    "                                  )\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=9, stride=1, padding=4, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        block1 = self.prelu(self.conv(x))\n",
    "        \n",
    "        block2 = self.resblock1(block1)\n",
    "        block2 = self.resblock1(block2)\n",
    "        block2 = self.resblock1(block2)\n",
    "        block2 = self.resblock1(block2)\n",
    "        block2 = self.resblock1(block2)\n",
    "\n",
    "        block2 = self.conv2(block2)\n",
    "        block2 = torch.add(block2, block1)\n",
    "\n",
    "        block2 = self.conv3(block2)\n",
    "        # block2 = self.conv3(block2)\n",
    "        block2 = self.conv4(block2)\n",
    "        return block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1576b6b4-5844-456a-b6a2-7bfdf352e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(DiscriminatorConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=stride, padding=1, bias=False), \n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.LeakyReLU(),\n",
    "                                 )\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa131a6a-11ce-4655-b6f4-ee6202273cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, low_res_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        img_d = int(low_res_dim / 8)\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False), \n",
    "                                  nn.LeakyReLU(),\n",
    "                                 )\n",
    "        self.conv2 = DiscriminatorConvBlock(64, 64, 2)\n",
    "        self.conv3 = DiscriminatorConvBlock(64, 128, 1)\n",
    "        self.conv4 = DiscriminatorConvBlock(128, 128, 2)\n",
    "        self.conv5 = DiscriminatorConvBlock(128, 256, 1)\n",
    "        self.conv6 = DiscriminatorConvBlock(256, 256, 2)\n",
    "        self.conv7 = DiscriminatorConvBlock(256, 512, 1)\n",
    "        self.conv8 = DiscriminatorConvBlock(512, 512, 2)\n",
    "\n",
    "        self.dense1 = nn.Linear(512 * img_d * img_d , 1024)\n",
    "        self.leakyRelu = nn.LeakyReLU()\n",
    "        self.dense2 = nn.Linear(1024 , 1)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = self.conv6(out)\n",
    "        out = self.conv7(out)\n",
    "        out = self.conv8(out)\n",
    "        out = out.view(-1, out.size(1) * out.size(2) * out.size(3))\n",
    "        out = self.leakyRelu(self.dense1(out))\n",
    "        out = torch.sigmoid(self.drop(self.dense2(out)))\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02969ed-78a8-4547-85c4-7eeeac6586dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "low_res = 128\n",
    "gen_model = Generator().to(device)\n",
    "disc_model = Discriminator(low_res).to(device)\n",
    "vgg = models.vgg19(pretrained=True).to(device)\n",
    "\n",
    "# gen_model = nn.DataParallel(gen_model, device_ids = [0, 1])\n",
    "# disc_model = nn.DataParallel(disc_model, device_ids = [0, 1])\n",
    "\n",
    "gen_optimizer = optim.Adam(gen_model.parameters(),lr=0.0001)\n",
    "disc_optimizer = optim.Adam(disc_model.parameters(),lr=0.0000001)\n",
    "gen_scheduler = CosineAnnealingWarmRestarts(gen_optimizer, \n",
    "                                        T_0 = 8,# Number of iterations for the first restart\n",
    "                                        T_mult = 1, # A factor increases TiTi​ after a restart\n",
    "                                        eta_min = 1e-6) # Minimum learning rate\n",
    "disc_scheduler = CosineAnnealingWarmRestarts(disc_optimizer, \n",
    "                                        T_0 = 8,# Number of iterations for the first restart\n",
    "                                        T_mult = 1, # A factor increases TiTi​ after a restart\n",
    "                                        eta_min = 1e-6) # Minimum learning rate\n",
    "mse_loss = nn.MSELoss()\n",
    "vgg_loss = nn.MSELoss()\n",
    "disc_loss = nn.BCELoss()\n",
    "print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "for epoch in range(num_epochs):\n",
    "    gen_scheduler.step()\n",
    "    disc_scheduler.step()\n",
    "    gen_optimizer.zero_grad()\n",
    "    dataloader = tqdm.tqdm(dataloader)\n",
    "    for i, data in enumerate(dataloader):\n",
    "        input_images, labels = data\n",
    "        # forward pass\n",
    "        input_images = input_images.to(device)\n",
    "        lowres_images = transforms.Resize(low_res)(input_images)\n",
    "        gen_highres_images = gen_model(lowres_images.to(device))\n",
    "\n",
    "        # print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "        # print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        # print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "        \n",
    "        # Discriminator\n",
    "        disc_model.zero_grad()\n",
    "        generated_label = disc_model(gen_highres_images.to(device))\n",
    "        actual_label = disc_model(input_images.to(device))\n",
    "        # print(\"generated_label: \", generated_label)\n",
    "        # print(\"actual_label: \", actual_label)\n",
    "        \n",
    "        \n",
    "        # Adversarial loss\n",
    "        d1_loss = (disc_loss(generated_label, torch.zeros_like(generated_label,dtype=torch.float)))\n",
    "        d2_loss = (disc_loss(actual_label, torch.ones_like(actual_label,dtype=torch.float)))\n",
    "        d2_loss.backward()\n",
    "        d1_loss.backward(retain_graph=True)\n",
    "        disc_optimizer.step()\n",
    "\n",
    "        gen_model.zero_grad() \n",
    "        # Perceptual loss\n",
    "        mse = mse_loss(input_images, gen_highres_images)\n",
    "        with torch.no_grad():\n",
    "            pred1 = vgg.features[:14](input_images)\n",
    "            pred2 = vgg.features[:14](gen_highres_images)\n",
    "        v_loss = vgg_loss(pred1, pred2)\n",
    "\n",
    "        generator_loss = mse + v_loss\n",
    "        \n",
    "        generator_loss.mean().backward()\n",
    "        gen_optimizer.step()\n",
    "        gen_optimizer.zero_grad()\n",
    "        torch.cuda.empty_cache()\n",
    "        # dataloader.set_description(\"Epoch %d Generator Loss %f    Discriminator Loss %f\" % (epoch, generator_loss.mean(), (d1_loss).mean()))\n",
    "        dataloader.set_description(\"Epoch %d Generator Loss %f Discriminator Loss %f Memory %f GB / %f GB\" % (epoch, generator_loss.mean(), (d1_loss).mean(), torch.cuda.memory_allocated(0)/1024/1024/1024, torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "        # print(\"MSE loss: \", v_loss)\n",
    "    if epoch % 1 ==0:\n",
    "        images, labels = next(iter(dataloader))\n",
    "        fig = plt.figure()\n",
    "        rows = 3\n",
    "        cols = 2\n",
    "        for ii in range(1, rows*cols + 1, 2):\n",
    "            lowres_image = transforms.Resize(low_res)(images[ii])\n",
    "            gen_highres_images = gen_model(torch.unsqueeze(lowres_image, 0).to(device))\n",
    "            \n",
    "            fig.add_subplot(rows, cols, ii)\n",
    "            plt.imshow(images[ii].permute(1, 2, 0))\n",
    "            plt.axis('off')\n",
    "            \n",
    "            fig.add_subplot(rows, cols, ii+1)\n",
    "            hires = transforms.ToPILImage()\n",
    "            plt.imshow(hires(gen_highres_images[0]))\n",
    "            plt.axis('off') \n",
    "    if epoch % 5 == 0:\n",
    "        checkpoint = {'model': Generator(),\n",
    "              'input_size': 256,\n",
    "              'output_size': 512,\n",
    "              'state_dict': gen_model.state_dict()}\n",
    "        torch.save(checkpoint,os.path.join(\"/home/aditya/Developer/repro/weights/\",\"SR\"+str(epoch+1)+\".pth\"))\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae7fb6-3de2-447a-9dee-94391f4db261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "    \n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1618212d-03c6-487e-b0a0-7b8d8ea217fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = load_checkpoint(\"/home/aditya/Developer/repro/weights/SR6.pth\").to(device)\n",
    "low_res = 64\n",
    "high_res = 256\n",
    "topil = transforms.ToPILImage()\n",
    "images, labels = next(iter(dataloader))\n",
    "fig = plt.figure()\n",
    "rows = 3\n",
    "cols = 2\n",
    "for ii in range(1, rows*cols + 1, 2):\n",
    "    lowres_image = transforms.Resize(low_res)(images[ii])\n",
    "    gen_highres_images = gen_model(torch.unsqueeze(lowres_image, 0).to(device))\n",
    "            \n",
    "    fig.add_subplot(rows, cols, ii)\n",
    "    plt.imshow(lowres_image.permute(1, 2, 0))\n",
    "    topil(transforms.Resize(high_res)(lowres_image)).save(\"resized.jpg\")\n",
    "    plt.axis('off')\n",
    "            \n",
    "    fig.add_subplot(rows, cols, ii+1)\n",
    "        \n",
    "    topil(gen_highres_images[0]).save(\"generated.jpg\")\n",
    "    plt.imshow(topil(gen_highres_images[0]))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec4e20-38f7-4a00-b0c5-7c82792baf73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
